2020-08-29 22:44:35.505435: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-08-29 22:44:35.526240: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2020-08-29 22:44:35.526292: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dmusial98-MSI): /proc/driver/nvidia/version does not exist
2020-08-29 22:44:35.526514: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-08-29 22:44:35.531519: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2799925000 Hz
2020-08-29 22:44:35.531864: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbeec000b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-29 22:44:35.531903: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Model: "vgg16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
vgg16 (Model)                (None, 7, 7, 512)         14714688  
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0         
_________________________________________________________________
dense (Dense)                (None, 256)               6422784   
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 257       
=================================================================
Total params: 21,137,729
Trainable params: 21,137,729
Non-trainable params: 0
_________________________________________________________________
Liczba wag poddawanych trenowaniu przed zamrozeniem bazy:  30
Liczba wag poddawanych trenowaniu po zamrozeniu bazy  4
Found 7500 images belonging to 10 classes.
Found 1500 images belonging to 10 classes.
WARNING:tensorflow:From main.py:67: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
Please use Model.fit, which supports generators.
Epoch 1/30
118/117 - 1349s - loss: 1.1921e-07 - acc: 0.8991 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 2/30
118/117 - 1234s - loss: 1.1921e-07 - acc: 0.8994 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 3/30
118/117 - 1173s - loss: 1.1921e-07 - acc: 0.8993 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 4/30
118/117 - 1165s - loss: 1.1921e-07 - acc: 0.8995 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 5/30
118/117 - 1110s - loss: 1.1921e-07 - acc: 0.8993 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 6/30
118/117 - 1099s - loss: 1.1921e-07 - acc: 0.8993 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 7/30
118/117 - 1101s - loss: 1.1921e-07 - acc: 0.8996 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 8/30
118/117 - 1098s - loss: 1.1921e-07 - acc: 0.8993 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 9/30
118/117 - 1094s - loss: 1.1921e-07 - acc: 0.8995 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 10/30
118/117 - 1093s - loss: 1.1921e-07 - acc: 0.8990 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 11/30
118/117 - 1094s - loss: 1.1921e-07 - acc: 0.8996 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 12/30
118/117 - 1096s - loss: 1.1921e-07 - acc: 0.8991 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 13/30
118/117 - 1108s - loss: 1.1921e-07 - acc: 0.8988 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 14/30
118/117 - 1098s - loss: 1.1921e-07 - acc: 0.8989 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 15/30
118/117 - 1096s - loss: 1.1921e-07 - acc: 0.8991 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 16/30
118/117 - 1098s - loss: 1.1921e-07 - acc: 0.8991 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 17/30
118/117 - 1100s - loss: 1.1921e-07 - acc: 0.8997 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 18/30
118/117 - 1097s - loss: 1.1921e-07 - acc: 0.8991 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 19/30
118/117 - 1097s - loss: 1.1921e-07 - acc: 0.8995 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 20/30
118/117 - 1096s - loss: 1.1921e-07 - acc: 0.8995 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 21/30
118/117 - 1096s - loss: 1.1921e-07 - acc: 0.8995 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 22/30
118/117 - 1096s - loss: 1.1921e-07 - acc: 0.8990 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 23/30
118/117 - 1095s - loss: 1.1921e-07 - acc: 0.8990 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 24/30
118/117 - 1097s - loss: 1.1921e-07 - acc: 0.8995 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 25/30
118/117 - 1096s - loss: 1.1921e-07 - acc: 0.8993 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 26/30
118/117 - 1094s - loss: 1.1921e-07 - acc: 0.8985 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 27/30
118/117 - 1096s - loss: 1.1921e-07 - acc: 0.8995 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 28/30
118/117 - 1092s - loss: 1.1921e-07 - acc: 0.8994 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 29/30
118/117 - 1093s - loss: 1.1921e-07 - acc: 0.8994 - val_loss: 1.1921e-07 - val_acc: 0.8995
Epoch 30/30
118/117 - 1104s - loss: 1.1921e-07 - acc: 0.8991 - val_loss: 1.1921e-07 - val_acc: 0.8995
